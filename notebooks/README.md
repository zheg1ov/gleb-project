# Exploratory Data Analysis (EDA)
## Введение
Цель данного исследования — провести разведочный анализ данных (EDA) по датасету качества воды, который содержит концентрации опасных веществ</b>
</p>
Основные задачи анализа:</p>

1. Загрузить и изучить структуру данных
2. Проверить полноту (Completeness) и уникальность записей (Uniqueness)
3. Оценить наличие выбросов и аномалий
4. Проанализировать распределения признаков
5. Изучить корреляции
6. Сделать аналитические выводы о целостности и структуре данных
## 1. Загрузка и первичный осмотр данных
Метод:
```python
raw_data = pd.read_csv(f"https://drive.google.com/uc?id={'1HXu3s_EKOPQ2Yk_FeNyw8PsIu3mWr8Te'}")
raw_data.info()
```
Результаты:
- Размер: 7999 строк × 21 столбцов
- Числовых признаков: 20
- Категориальных признаков: 1
- Типы данных определены корректно (int64 и object)</p>
</p>
Комментарий: Датасет структурирован и готов к анализу. Все поля читаются корректно, данные полные и чистые.


## 2. Оценка полноты данных (Completeness)
Метод:

```python
for i in col:
  # Создание списка для проверки есть ли Nan в столбце
  isnull_list = list(df[i].isnull().unique())

  # если в списке True (Nan значения) и False (не Nan значения)
  if len(isnull_list) == 2:

    # Подсчет процента Nan от общего числа строк и округление до 1 знака
    proc_nan = np.round(len(df[df[i].isnull() == True]) / len(df[i]) * 100, 1)
    print(f'{j}. Колонка {i} на {proc_nan}% состоит из Nan')

  else:
    if isnull_list[0] == False:
      print(f'{j}. Колонка {i} просто СУПЕР, вообще нет Nan')

    else:
      print(f'{j}. Колонка {i} полный ОТСТОЙ, тут только Nan')

  j += 1
```

Результаты:
- Колонка ammonia на 0.0% состоит из Nan
- Колонка is_safe на 0.0% состоит из Nan
Количества Nan меньше 0.01%, поэтому спокойно удаляем:

```python
df = df.dropna(how='any')
```

Вывод: Все записи уникальны, идентификатор сотрудников (EmployeeNumber) корректен. Структура данных целостная и без дубликатов

## 3. Оценка уникальности записей (Uniqueness)
Метод:

```python
print(f"Количество дубликатов: {df.duplicated().sum()}")
print(f"Процент дубликатов: {(df.duplicated().sum() / len(df)) * 100:.2f}%")
```

Результаты:
- Количество дубликатов: 0
- Процент дубликатов: 0.00% </p>
Вывод: Все записи уникальны, идентификатор сотрудников (EmployeeNumber) корректен. Структура данных целостная и без дубликатов.

## 4. Оценка выбросов и аномалий
Метод: IQR

```python
plt.figure(figsize=(12, 6))
df[numeric_columns].boxplot()
plt.xticks(rotation=45)
plt.title('Boxplot для всех числовых колонок')
plt.show()
print(df.describe())

# Проверка на аномальные значения
def check_anomalies(df):
    anomalies = {}
    for column in df.select_dtypes(include=[np.number]).columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
        anomalies[column] = len(outliers)
    
    return anomalies
#
anomalies = check_anomalies(df)
for col, count in anomalies.items():
    if count > 0:
        print(f"{col}: {count} аномалий ({count/len(df)*100:.2f}%)")
```
<img width="979" height="580" alt="image" src="https://github.com/user-attachments/assets/3ea9e774-7ffb-4ffe-bf61-28806d1a9d85" />
Признаки с наибольшим количеством выбросов:
- aluminium: 1731 аномалий (21.65%)
- arsenic: 1634 аномалий (20.44%)
- nitrites: 2 аномалий (0.03%) </p>
</p>
Комментарий: Мы видим приличное количество выбросов, но удалять я их не буду в силу природы данных. Выбросы здесь — не ошибки измерений, а реальные опасные уровни загрязнения, которые как раз и определяют, безопасна ли вода и если удалить такие значения, я потеряю важные паттерны, связанные с опасной водой. Целевая переменная is_safe вычисляется по пороговым значениям для каждого показателя, а значит если хотя бы один показатель превышает свой порог — вода считается небезопасной. По этим причинам я оставлю выбросы.

## 5. Визуализация распределений и выбросов
Распределение числовых признаков:
```python
plot_numeric_grid(df, df.columns, ncols=3, figsize=(14, 18))
```
<img width="1387" height="1790" alt="image" src="https://github.com/user-attachments/assets/f27172cf-01ed-497c-8ede-68bb863f1287" />

Результаты: 
- Большинство признаков имеют нормальное распределение, либо нормальное, смещенное влево
- ammonia, nitrates, flouride, lead - постоянные значения (низкая дисперсия).

## 6. Корреляционный анализ
Матрица корреляций:

```python
sns.heatmap(correlation_matrix, cmap='Blues')
```
<img width="1318" height="1190" alt="image" src="https://github.com/user-attachments/assets/7e63058e-ca5b-49f4-9645-f9cc67a6cc43" />

Результаты: Как и ожидалось, признаки практически не коррелируют с целевой переменной, так как сами концентрации не важны - важен факт выхода из норматива.

## 7. Сохранение промежуточных результатов
```python
df.to_csv('notebooks/output/clean_data.csv')
```
## Заключение

| Метрика | Значение | Комментарий |
|-------------|-------------|-------------|
| Completeness    | 1.00  | Данные не пропущены   |
| Uniqueness    | 1.00  | Все записи уникальны  |
| Data Consistency    | высокая    | типы и структура корректны   |


Общие выводы:

- Датасет чистый, структурированный, с хорошим качеством данных
- Выбросы не искажают общую структуру
- Корреляции логичны </p>

Рекомендации:Для дальнейшего предсказания стоит использовать oversampling, чтобы дизбаланс не повлиял на качество модели
